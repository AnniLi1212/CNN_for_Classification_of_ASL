{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import random_split\n",
    "from torchvision.transforms import v2\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math\n",
    "import time\n",
    "import os\n",
    "import glob\n",
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "import mediapipe as mp\n",
    "\n",
    "from dataProcess import getDataLoader\n",
    "from dataProcess import plot_images\n",
    "from modelProcess import count_params\n",
    "from modelProcess import modelTrain\n",
    "from modelEvaluation import plotCurve\n",
    "from modelEvaluation import applyModeltoTest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up the device\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')          \n",
    "    print(f'Using GPU: {torch.cuda.get_device_name(0)}')\n",
    "elif torch.backends.mps.is_built():\n",
    "    device = 'mps' \n",
    "    print(f'using {device}')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    print(f'using {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to process images by mediapipe\n",
    "def process_images(input_folder, output_folder):\n",
    "    # create mediapipe model\n",
    "    mp_hands = mp.solutions.hands\n",
    "    hands = mp_hands.Hands(static_image_mode=True, \n",
    "                           max_num_hands=1, \n",
    "                           min_detection_confidence=0.5)\n",
    "    \n",
    "    # go through each subfolder\n",
    "    for class_folder in os.listdir(input_folder):\n",
    "        input_class_path = os.path.join(input_folder, class_folder)\n",
    "        output_class_path = os.path.join(output_folder, class_folder)\n",
    "\n",
    "        # create output subfolder\n",
    "        if not os.path.exists(output_class_path):\n",
    "            os.makedirs(output_class_path)\n",
    "\n",
    "        for image_path in glob.glob(os.path.join(input_class_path, '*.jpg')):\n",
    "            # read and convert the image to rgb\n",
    "            image = Image.open(image_path)\n",
    "            image_rgb = np.array(image.convert('RGB'))\n",
    "\n",
    "            # process through mediapipe model\n",
    "            results = hands.process(image_rgb)\n",
    "            if results.multi_hand_landmarks:\n",
    "                # drop the marks on image\n",
    "                for hand_landmarks in results.multi_hand_landmarks:\n",
    "                    mp.solutions.drawing_utils.draw_landmarks(image_rgb, hand_landmarks, mp_hands.HAND_CONNECTIONS)\n",
    "\n",
    "            # save the output image\n",
    "            image_mp = Image.fromarray(image_rgb)\n",
    "            base_name = os.path.basename(image_path)\n",
    "            image_mp.save(os.path.join(output_class_path, base_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_folder = 'data/asl_alphabet_train'\n",
    "output_folder = 'data/asl_alphabet_train_mp'\n",
    "process_images(input_folder, output_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = 'data/asl_alphabet_train'\n",
    "loader_train, loader_val, loader_test=getDataLoader(folder,batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_images(loader_train,16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_images(loader_test,16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class improvedCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(improvedCNN, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, padding=1)\n",
    "        \n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2)\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=5)\n",
    "        \n",
    "        self.fc1 = nn.Linear(32 * 20 * 20, 512)\n",
    "        self.fc2 = nn.Linear(512, 29)\n",
    "        \n",
    "        self.flatten = nn.Flatten()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.pool1(F.relu(self.conv1(x)))\n",
    "        x = self.pool2(F.relu(self.conv2(x)))\n",
    "        \n",
    "        x = self.flatten(x)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = improvedCNN()\n",
    "count_params(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs=20\n",
    "losses_train, accs_train, losses_val, accs_val, train_time=modelTrain(model=model,learning_rate=0.00015,num_epochs=num_epochs,loader_train=loader_train,loader_val=loader_val,device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotCurve(num_epochs, losses_train, accs_train, losses_val, accs_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(applyModeltoTest(model=model,loader_test=loader_test,device=device))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
