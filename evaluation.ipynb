{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a73e5f41",
   "metadata": {},
   "source": [
    "### Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06446ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import random_split\n",
    "from torchvision.transforms import v2\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from PIL import Image\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math\n",
    "import time\n",
    "import os\n",
    "import glob\n",
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.metrics import average_precision_score, precision_recall_curve\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import PrecisionRecallDisplay\n",
    "\n",
    "import mediapipe as mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bcf7a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up the device\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')          \n",
    "    print(f'Using GPU: {torch.cuda.get_device_name(0)}')\n",
    "elif torch.backends.mps.is_built():\n",
    "    device = 'mps' \n",
    "    print(f'using {device}')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    print(f'using {device}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7904ed1",
   "metadata": {},
   "source": [
    "### Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad2ea779",
   "metadata": {},
   "outputs": [],
   "source": [
    "# unzip the dataset: please manually download at https://www.kaggle.com/datasets/grassknoted/asl-alphabet/data\n",
    "!tar -xvzf data/asl_alphabet_train.zip -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "151d34e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to normalize images\n",
    "def normalize_image(tensorimage):\n",
    "    image_min = tensorimage.min()\n",
    "    image_max = tensorimage.max()\n",
    "    tensorimage.clamp_(min=image_min, max=image_max)\n",
    "    tensorimage.add_(-image_min).div_(image_max - image_min + 1e-5)\n",
    "    return tensorimage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19218ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to get class name from numeric label\n",
    "def get_class(dataloader, label):\n",
    "    # define the class to label dictionary\n",
    "    class2label = dataloader.dataset.dataset.class_to_idx\n",
    "    # revert the dictionary\n",
    "    label2class = {v: k for k, v in class2label.items()}\n",
    "\n",
    "    # return the corresponding class name and print error if label is undefined\n",
    "    return label2class.get(label, 'label not found')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2ebeae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to process images by mediapipe\n",
    "def process_images(input_folder, output_folder):\n",
    "    # create mediapipe model\n",
    "    mp_hands = mp.solutions.hands\n",
    "    hands = mp_hands.Hands(static_image_mode=True, \n",
    "                           max_num_hands=1, \n",
    "                           min_detection_confidence=0.5)\n",
    "    \n",
    "    # go through each subfolder\n",
    "    for class_folder in os.listdir(input_folder):\n",
    "        input_class_path = os.path.join(input_folder, class_folder)\n",
    "        output_class_path = os.path.join(output_folder, class_folder)\n",
    "\n",
    "        # create output subfolder\n",
    "        if not os.path.exists(output_class_path):\n",
    "            os.makedirs(output_class_path)\n",
    "\n",
    "        for image_path in glob.glob(os.path.join(input_class_path, '*.jpg')):\n",
    "            # read and convert the image to rgb\n",
    "            image = Image.open(image_path)\n",
    "            image_rgb = np.array(image.convert('RGB'))\n",
    "\n",
    "            # process through mediapipe model\n",
    "            results = hands.process(image_rgb)\n",
    "            if results.multi_hand_landmarks:\n",
    "                # drop the marks on image\n",
    "                for hand_landmarks in results.multi_hand_landmarks:\n",
    "                    mp.solutions.drawing_utils.draw_landmarks(image_rgb, hand_landmarks, mp_hands.HAND_CONNECTIONS)\n",
    "\n",
    "            # save the output image\n",
    "            image_mp = Image.fromarray(image_rgb)\n",
    "            base_name = os.path.basename(image_path)\n",
    "            image_mp.save(os.path.join(output_class_path, base_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acdc1083",
   "metadata": {},
   "outputs": [],
   "source": [
    "# process images\n",
    "input_folder = 'data/asl_alphabet_train'\n",
    "output_folder = 'data/asl_alphabet_train_mp'\n",
    "process_images(input_folder, output_folder)\n",
    "# load the dataset\n",
    "folder_mp = 'data/asl_alphabet_train_mp'\n",
    "dataset_mp = ImageFolder(root=folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fce3a72b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for val and test transforms\n",
    "transforms_valtest = v2.Compose([\n",
    "    # transform to tensor\n",
    "    v2.ToImage(),\n",
    "    v2.ToDtype(torch.float32, scale=True),\n",
    "    # normalize\n",
    "    normalize_image,\n",
    "    # crop the image\n",
    "    v2.Resize(size=(200, 200), antialias=True)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21b52ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataset\n",
    "folder = 'data/asl_alphabet_train'\n",
    "dataset = ImageFolder(root=folder)\n",
    "\n",
    "# number of images in the dataset\n",
    "dataset_size = len(dataset)\n",
    "\n",
    "# define split sizes; avoid rounding errors\n",
    "size_train = int(dataset_size / 10 * 7)\n",
    "size_val = int(dataset_size / 10 * 1.5)\n",
    "size_test = int(dataset_size / 10 * 1.5)\n",
    "\n",
    "# split the dataset\n",
    "dataset_train, dataset_val, dataset_test = random_split(dataset, \n",
    "                                                        [int(size_train), \n",
    "                                                         int(size_val), \n",
    "                                                         int(size_test)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c297b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of images in the dataset\n",
    "dataset_size_mp = len(dataset_mp)\n",
    "\n",
    "# define split sizes; avoid rounding errors\n",
    "size_train_mp = int(dataset_size_mp / 10 * 7)\n",
    "size_val_mp = int(dataset_size_mp / 10 * 1.5)\n",
    "size_test_mp = int(dataset_size_mp / 10 * 1.5)\n",
    "\n",
    "# split the dataset\n",
    "dataset_train_mp, dataset_val_mp, dataset_test_mp = random_split(dataset_mp, \n",
    "                                                        [int(size_train_mp), \n",
    "                                                         int(size_val_mp), \n",
    "                                                         int(size_test_mp)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "902848ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_test.dataset = ImageFolder(root=folder, transform=transforms_valtest)\n",
    "dataset_test_mp.dataset = ImageFolder(root=folder_mp, transform=transforms_valtest)\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "loader_test = DataLoader(dataset_test, batch_size=batch_size, shuffle=False)\n",
    "loader_test_mp = DataLoader(dataset_test_mp, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83085e0c",
   "metadata": {},
   "source": [
    "### Model Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09970011",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BasicCNN, self).__init__()\n",
    "        \n",
    "        # block1, 200x200\n",
    "        self.conv1a = nn.Conv2d(3, 8, kernel_size=3, padding=1)\n",
    "        self.bn1a = nn.BatchNorm2d(8)\n",
    "        self.conv1b = nn.Conv2d(8, 16, kernel_size=3, padding=1)\n",
    "        self.bn1b = nn.BatchNorm2d(16)\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2)\n",
    "        \n",
    "        # block2, 100x100\n",
    "        self.conv2a = nn.Conv2d(16, 32, kernel_size=3, padding=1)\n",
    "        self.bn2a = nn.BatchNorm2d(32)\n",
    "        self.conv2b = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.bn2b = nn.BatchNorm2d(64)\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2)\n",
    "        \n",
    "        # block3, 50x50\n",
    "        self.conv3a = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.bn3a = nn.BatchNorm2d(128)\n",
    "        self.conv3b = nn.Conv2d(128, 128, kernel_size=3, padding=1)\n",
    "        self.bn3b = nn.BatchNorm2d(128)\n",
    "        self.pool3 = nn.MaxPool2d(kernel_size=5)\n",
    "\n",
    "        self.dropout = nn.Dropout2d(0.3)\n",
    "        \n",
    "        # linear layers, 25x25\n",
    "        self.fc1 = nn.Linear(128 * 10 * 10, 512)\n",
    "        self.fc2 = nn.Linear(512, 29)\n",
    "        \n",
    "        self.flatten = nn.Flatten()\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.bn1a(self.conv1a(x)))\n",
    "        x = F.relu(self.bn1b(self.conv1b(x)))\n",
    "        x = self.pool1(x)\n",
    "        \n",
    "        x = F.relu(self.bn2a(self.conv2a(x)))\n",
    "        x = F.relu(self.bn2b(self.conv2b(x)))\n",
    "        x = self.pool2(x)\n",
    "        \n",
    "        x = F.relu(self.bn3a(self.conv3a(x)))\n",
    "        x = F.relu(self.bn3b(self.conv3b(x)))\n",
    "        x = self.pool3(x)\n",
    "        \n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        x = self.flatten(x)\n",
    "        \n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd5dfb1d",
   "metadata": {},
   "source": [
    "### Regular Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f68c6fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "model = BasicCNN()\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d36f2613",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_test = 0.0\n",
    "acc_test = 0.0\n",
    "# load the best model\n",
    "model.load_state_dict(torch.load('best_models/best_model_baseline.pth', map_location=torch.device('cpu')))\n",
    "#model.load_state_dict(torch.load('best_models/best_model_baseline.pth'))\n",
    "model = model.to(device)\n",
    "\n",
    "model.eval()\n",
    "\n",
    "for inputs, labels in loader_test:\n",
    "    inputs, labels = inputs.to(device), labels.to(device)\n",
    "    \n",
    "    # disable gradient computation\n",
    "    with torch.no_grad():\n",
    "        \n",
    "        # forward\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        acc = torch.sum(torch.eq(torch.max(outputs, axis=1).indices, labels))\n",
    "        \n",
    "        # add up loss and acc\n",
    "        loss_test += loss.item()\n",
    "        acc_test += acc.item()\n",
    "\n",
    "# get average loss and acc\n",
    "loss_test_avg = loss_test / len(loader_test)\n",
    "acc_test_avg = acc_test / len(loader_test.dataset)\n",
    "\n",
    "print(f'test loss: {loss_test_avg:.2f}, test acc: {acc_test_avg:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5ed3fd5",
   "metadata": {},
   "source": [
    "### Trained on Skeleton Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "494c4b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion_mp = nn.CrossEntropyLoss()\n",
    "model_mp = BasicCNN()\n",
    "model_mp = model_mp.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc03a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test\n",
    "loss_test_mp = 0.0\n",
    "acc_test_mp = 0.0\n",
    "# load the best model\n",
    "model.load_state_dict(torch.load('best_models/best_model_skeleton.pth', map_location=torch.device('cpu')))\n",
    "#model_mp.load_state_dict(torch.load('best_models/best_model_skeleton.pth'))\n",
    "model_mp = model_mp.to(device)\n",
    "\n",
    "model_mp.eval()\n",
    "\n",
    "for inputs, labels in loader_test_mp:\n",
    "    inputs, labels = inputs.to(device), labels.to(device)\n",
    "    \n",
    "    # disable gradient computation\n",
    "    with torch.no_grad():\n",
    "        \n",
    "        # forward\n",
    "        outputs = model_mp(inputs)\n",
    "        loss = criterion_mp(outputs, labels)\n",
    "        acc = torch.sum(torch.eq(torch.max(outputs, axis=1).indices, labels))\n",
    "        \n",
    "        # add up loss and acc\n",
    "        loss_test_mp += loss.item()\n",
    "        acc_test_mp += acc.item()\n",
    "\n",
    "# get average loss and acc\n",
    "loss_test_avg_mp = loss_test_mp / len(loader_test_mp)\n",
    "acc_test_avg_mp = acc_test_mp / len(loader_test_mp.dataset)\n",
    "\n",
    "print(f'test loss: {loss_test_avg_mp:.2f}, test acc: {acc_test_avg_mp:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a2af57d",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb52e2bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot heatmap of confusion matrix\n",
    "num_classes = 29\n",
    "classes = [get_class(loader_test, i) for i in range(num_classes)]\n",
    "confusion_matrix = np.zeros((num_classes, num_classes))\n",
    "count = np.zeros((num_classes))\n",
    "for inputs, labels in loader_test:\n",
    "    inputs, labels = inputs.to(device), labels.to(device)\n",
    "    # disable gradient computation\n",
    "    with torch.no_grad():\n",
    "        # forward\n",
    "        outputs = model(inputs)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "\n",
    "        # prediction and create confusion matrix\n",
    "        for true, pred in zip(labels, preds):\n",
    "            confusion_matrix[true, pred] += 1\n",
    "            count[true.long()] += 1\n",
    "            \n",
    "plt.figure(figsize=[12,10])\n",
    "# create dataframe to hold the matrix\n",
    "df = pd.DataFrame(100 * confusion_matrix / count)\n",
    "# create heatmap\n",
    "ax = sn.heatmap(df, vmin=0, vmax=100, cmap='turbo', annot=True, fmt='.2f', annot_kws={'size':6}, linewidths=0.5, xticklabels=classes, yticklabels=classes)\n",
    "ax.set_xlabel('True')\n",
    "ax.set_ylabel('Prediction')\n",
    "ax.set_title('Confusion Matrix for Baseline Model')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8625c753",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot heatmap of confusion matrix for skeleton model\n",
    "num_classes = 29\n",
    "classes_mp = [get_class(loader_test_mp, i) for i in range(num_classes)]\n",
    "confusion_matrix_mp = np.zeros((num_classes, num_classes))\n",
    "count_mp = np.zeros((num_classes))\n",
    "for inputs, labels in loader_test_mp:\n",
    "    inputs, labels = inputs.to(device), labels.to(device)\n",
    "    # disable gradient computation\n",
    "    with torch.no_grad():\n",
    "        # forward\n",
    "        outputs = model_mp(inputs)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "\n",
    "        # prediction and create confusion matrix\n",
    "        for true, pred in zip(labels, preds):\n",
    "            confusion_matrix_mp[true, pred] += 1\n",
    "            count_mp[true.long()] += 1\n",
    "            \n",
    "plt.figure(figsize=[12,10])\n",
    "# create dataframe to hold the matrix\n",
    "df_mp = pd.DataFrame(100 * confusion_matrix_mp / count_mp)\n",
    "# create heatmap\n",
    "ax = sn.heatmap(df_mp, vmin=0, vmax=100, cmap='turbo', annot=True, fmt='.2f', annot_kws={'size':6}, linewidths=0.5, xticklabels=classes, yticklabels=classes)\n",
    "ax.set_xlabel('True')\n",
    "ax.set_ylabel('Prediction')\n",
    "ax.set_title('Confusion Matrix for Skeleton Model')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "297962a1",
   "metadata": {},
   "source": [
    "### Precision and Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d3fffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate precision and recall for baseline model\n",
    "matrix = np.array(df)\n",
    "# calculate TP, FP, FN and store in arrays\n",
    "TP = np.diag(matrix)\n",
    "FP = np.sum(matrix, axis=0) - TP\n",
    "FN = np.sum(matrix, axis=1) - TP\n",
    "# calculate precision and recall\n",
    "precision = TP / (TP + FP)\n",
    "recall = TP / (TP + FN)\n",
    "print('Precision and Recall for each class of Baseline Model')\n",
    "for i in range(num_classes):\n",
    "    print(f'class {i+1}: precision = {precision[i]:.2f}, recall = {recall[i]:.2f}')\n",
    "\n",
    "lowest_precision_ind = np.argmin(precision)\n",
    "lowest_precision_label = get_class(loader_test, lowest_precision_ind)\n",
    "lowest_recall_ind = np.argmin(recall)\n",
    "lowest_recall_label = get_class(loader_test, lowest_recall_ind)\n",
    "\n",
    "print(f'Lowest precision is {precision[lowest_precision_ind]} on class {lowest_precision_ind+1}, label {lowest_precision_label}')\n",
    "print(f'Lowest recall is {recall[lowest_recall_ind]} on class {lowest_recall_ind+1}, label {lowest_recall_label}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50404df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate precision and recall for skeleton model\n",
    "matrix_mp = np.array(df_mp)\n",
    "# calculate TP, FP, FN and store in arrays\n",
    "TP_mp = np.diag(matrix_mp)\n",
    "FP_mp = np.sum(matrix_mp, axis=0) - TP_mp\n",
    "FN_mp = np.sum(matrix_mp, axis=1) - TP_mp\n",
    "# calculate precision and recall\n",
    "precision_mp = TP_mp / (TP_mp + FP_mp)\n",
    "recall_mp = TP_mp / (TP_mp + FN_mp)\n",
    "print('Precision and Recall for each class of Skeleton Model')\n",
    "for i in range(num_classes):\n",
    "    print(f'class {i+1}: precision = {precision_mp[i]:.2f}, recall = {recall_mp[i]:.2f}')\n",
    "    \n",
    "lowest_precision_ind_mp = np.argmin(precision_mp)\n",
    "lowest_precision_label_mp = get_class(loader_test_mp, lowest_precision_ind_mp)\n",
    "lowest_recall_ind_mp = np.argmin(recall_mp)\n",
    "lowest_recall_label_mp = get_class(loader_test_mp, lowest_recall_ind_mp)\n",
    "\n",
    "print(f'Lowest precision is {precision_mp[lowest_precision_ind_mp]} on class {lowest_precision_ind_mp+1}, label {lowest_precision_label_mp}')\n",
    "print(f'Lowest recall is {recall_mp[lowest_recall_ind_mp]} on class {lowest_recall_ind_mp+1}, label {lowest_recall_label_mp}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dabdbd1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Baseline Model\n",
    "# get true label and predicted labels as one-hot\n",
    "y_test = []\n",
    "y_score = []\n",
    "model.eval()\n",
    "for inputs, labels in loader_test:\n",
    "    inputs, labels = inputs.to(device), labels.to(device)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(inputs)\n",
    "        preds = torch.softmax(outputs, dim=1)\n",
    "        y_score.append(preds)\n",
    "        y_test.append(labels)\n",
    "# Concatenate all the collected data\n",
    "y_score = torch.cat(y_score).cpu().numpy()\n",
    "y_test = torch.cat(y_test).cpu().numpy()\n",
    "y_test = [get_class(loader_test, i) for i in y_test]\n",
    "y_test = label_binarize(y_test, classes=classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94c0a0a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision = dict()\n",
    "recall = dict()\n",
    "average_precision = dict()\n",
    "for i in range(num_classes):\n",
    "    precision[i], recall[i], _ = precision_recall_curve(y_test[:, i], y_score[:, i])\n",
    "    average_precision[i] = average_precision_score(y_test[:, i], y_score[:, i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "042757a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, ax = plt.subplots(figsize=(10, 10))\n",
    "for i in range(num_classes):\n",
    "    display = PrecisionRecallDisplay(\n",
    "        recall=recall[i],\n",
    "        precision=precision[i],\n",
    "        average_precision=average_precision[i])\n",
    "    display.plot(ax=ax, name=f'class {i+1}')\n",
    "ax.set_xlim([0.0, 1])\n",
    "ax.set_ylim([0.0, 1.05])\n",
    "ax.legend()\n",
    "ax.set_title('Precision-Recall Curve for Baseline Model')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9adb944",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for Skeleton Model\n",
    "# get true label and predicted labels as one-hot\n",
    "y_test_mp = []\n",
    "y_score_mp = []\n",
    "model_mp.eval()\n",
    "for inputs, labels in loader_test_mp:\n",
    "    inputs, labels = inputs.to(device), labels.to(device)\n",
    "    with torch.no_grad():\n",
    "        outputs = model_mp(inputs)\n",
    "        preds = torch.softmax(outputs, dim=1)\n",
    "        y_score_mp.append(preds)\n",
    "        y_test_mp.append(labels)\n",
    "# Concatenate all the collected data\n",
    "y_score_mp = torch.cat(y_score_mp).cpu().numpy()\n",
    "y_test_mp = torch.cat(y_test_mp).cpu().numpy()\n",
    "y_test_mp = [get_class(loader_test_mp, i) for i in y_test_mp]\n",
    "y_test_mp = label_binarize(y_test_mp, classes=classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85cd63ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_mp = dict()\n",
    "recall_mp = dict()\n",
    "average_precision_mp = dict()\n",
    "for i in range(num_classes):\n",
    "    precision_mp[i], recall_mp[i], _ = precision_recall_curve(y_test_mp[:, i], y_score_mp[:, i])\n",
    "    average_precision_mp[i] = average_precision_score(y_test_mp[:, i], y_score_mp[:, i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45fded02",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, ax = plt.subplots(figsize=(10, 10))\n",
    "for i in range(num_classes):\n",
    "    display = PrecisionRecallDisplay(\n",
    "        recall=recall_mp[i],\n",
    "        precision=precision_mp[i],\n",
    "        average_precision=average_precision_mp[i])\n",
    "    display.plot(ax=ax, name=f'class {i+1}')\n",
    "ax.set_xlim([0.0, 1])\n",
    "ax.set_ylim([0.0, 1.05])\n",
    "ax.legend()\n",
    "ax.set_title('Precision-Recall Curve for Skeleton Model')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
